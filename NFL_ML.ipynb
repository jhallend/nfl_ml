{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b94b5ca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/jhallend/nfl_ml\r\n",
      " * branch            main       -> FETCH_HEAD\r\n",
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e0b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hint: Waiting for your editor to close the file... \u001b7\u001b[?47h\u001b[?1h\u001b=\u001b[?2004h\u001b[1;24r\u001b[m\u001b[H\u001b[2J\u001b[24;1H\"~/SageMaker/nfl_ml/.git/COMMIT_EDITMSG\" 15L, 391C\u001b[2;1H# Please enter the commit message for your changes. Lines starting\n",
      "# with '#' will be ignored, and an empty message aborts the commit.\n",
      "#\n",
      "# Committer: EC2 Default User <ec2-user@ip-172-16-49-156.us-east-2.compute.interr\u001b[6;1Hnal>\n",
      "#\n",
      "# On branch main\n",
      "# Your branch is up to date with 'origin/main'.\n",
      "#\n",
      "# Changes to be committed:\n",
      "#\u001b[7Cmodified:   NFL_ML.ipynb\n",
      "#\n",
      "# Untracked files:\n",
      "#\u001b[7C.ipynb_checkpoints/\n",
      "#\n",
      "\u001b[1m\u001b[34m~                                                                               \u001b[18;1H~                                                                               \u001b[19;1H~                                                                               \u001b[20;1H~                                                                               \u001b[21;1H~                                                                               \u001b[22;1H~                                                                               \u001b[23;1H~                                                                               \u001b[1;1H\u001b[m\u001b[24;1HType  :quit<Enter>  to exit Vim\u001b[24;32H\u001b[K\u0007\u001b[1;1H"
     ]
    }
   ],
   "source": [
    "!git commit NFL_ML.ipynb -m \"committing just \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f64206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/OpenSSL/crypto.py:12: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\n",
      "  from cryptography import x509\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/OpenSSL/crypto.py:12: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\n",
      "  from cryptography import x509\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/OpenSSL/crypto.py:12: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\n",
      "  from cryptography import x509\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git push origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b490724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Requirement already satisfied: keras in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from keras) (1.16.5)\n",
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (1.15.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (0.14.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.0.post1)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.16.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (2.3.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.1.6)\n",
      "Requirement already satisfied: mock>=2.0.0; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (3.0.5)\n",
      "Requirement already satisfied: functools32>=3.2.3; python_version < \"3\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (3.2.3.post2)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (1.15.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: futures>=2.2.0; python_version < \"3.2\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from grpcio>=1.8.6->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from mock>=2.0.0; python_version < \"3\"->tensorflow) (1.0.2)\n",
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-0.82-py2.py3-none-manylinux1_x86_64.whl (114.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 114.0 MB 105.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from xgboost) (1.2.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from xgboost) (1.16.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n",
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced-learn-0.8.1.tar.gz (347 kB)\n",
      "\u001b[K     |████████████████████████████████| 347 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from imbalanced-learn->imblearn) (1.16.5)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn>=0.24 (from imbalanced-learn->imblearn) (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0b1, 0.15.0b2, 0.15.0, 0.15.1, 0.15.2, 0.16b1, 0.16.0, 0.16.1, 0.17b1, 0.17, 0.17.1, 0.18rc2, 0.18, 0.18.1, 0.18.2, 0.19b2, 0.19.0, 0.19.1, 0.19.2, 0.20rc1, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21rc2)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for scikit-learn>=0.24 (from imbalanced-learn->imblearn)\u001b[0m\n",
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Collecting cvxpy\n",
      "  Downloading cvxpy-1.0.31.tar.gz (947 kB)\n",
      "\u001b[K     |████████████████████████████████| 947 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages (from cvxpy) (1.16.5)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2.zip (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 73.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ecos>=2\n",
      "  Downloading ecos-2.0.7.post1-cp27-cp27mu-manylinux1_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 114.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting osqp>=0.4.1\n",
      "  Downloading osqp-0.6.2.post0.tar.gz (219 kB)\n",
      "\u001b[K     |████████████████████████████████| 219 kB 119.4 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/bin/python /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-a1ffiP/normal --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- qdldl\n",
      "       cwd: None\n",
      "  Complete output (140 lines):\n",
      "  DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\n",
      "  Collecting qdldl\n",
      "    Downloading qdldl-0.1.5.post0.tar.gz (69 kB)\n",
      "  Collecting numpy>=1.7\n",
      "    Using cached numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl (17.0 MB)\n",
      "  Collecting scipy>=0.13.2\n",
      "    Using cached scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8 MB)\n",
      "  Building wheels for collected packages: qdldl\n",
      "    Building wheel for qdldl (setup.py): started\n",
      "    Building wheel for qdldl (setup.py): finished with status 'error'\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-ihyb00/qdldl/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-ihyb00/qdldl/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-2RBImG\n",
      "         cwd: /tmp/pip-install-ihyb00/qdldl/\n",
      "    Complete output (68 lines):\n",
      "    running bdist_wheel\n",
      "    running build\n",
      "    running build_ext\n",
      "    -- The C compiler identification is GNU 4.8.5\n",
      "    -- The CXX compiler identification is GNU 4.8.5\n",
      "    -- Detecting C compiler ABI info\n",
      "    -- Detecting C compiler ABI info - done\n",
      "    -- Check for working C compiler: /usr/bin/gcc - skipped\n",
      "    -- Detecting C compile features\n",
      "    -- Detecting C compile features - done\n",
      "    -- Detecting CXX compiler ABI info\n",
      "    -- Detecting CXX compiler ABI info - done\n",
      "    -- Check for working CXX compiler: /usr/bin/g++ - skipped\n",
      "    -- Detecting CXX compile features\n",
      "    -- Detecting CXX compile features - done\n",
      "    -- Floats are OFF\n",
      "    -- Long integers (64bit) are ON\n",
      "    -- Configuring done\n",
      "    -- Generating done\n",
      "    -- Build files have been written to: /tmp/pip-install-ihyb00/qdldl/c/build\n",
      "    [  6%] Building C object qdldl/CMakeFiles/qdldlobject.dir/src/qdldl.c.o\n",
      "    [  6%] Built target qdldlobject\n",
      "    [ 13%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_1.c.o\n",
      "    [ 20%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_2.c.o\n",
      "    [ 26%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_aat.c.o\n",
      "    [ 33%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_control.c.o\n",
      "    [ 40%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_defaults.c.o\n",
      "    [ 46%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_info.c.o\n",
      "    [ 53%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_order.c.o\n",
      "    [ 60%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_post_tree.c.o\n",
      "    [ 66%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_postorder.c.o\n",
      "    [ 73%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_preprocess.c.o\n",
      "    [ 80%] Building C object CMakeFiles/qdldlamd.dir/amd/src/amd_valid.c.o\n",
      "    [ 86%] Building C object CMakeFiles/qdldlamd.dir/amd/src/SuiteSparse_config.c.o\n",
      "    [ 93%] Building C object CMakeFiles/qdldlamd.dir/amd/src/perm.c.o\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c: In function ‘permute_x’:\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:23:5: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "         for (QDLDL_int j = 0 ; j < n ; j++) x[j] = b[P[j]];\n",
      "         ^\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:23:5: note: use option -std=c99 or -std=gnu99 to compile your code\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c: In function ‘permutet_x’:\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:28:5: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "         for (QDLDL_int j = 0 ; j < n ; j++) x[P[j]] = b[j];\n",
      "         ^\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c: In function ‘pinv’:\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:33:3: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "       for (QDLDL_int k = 0; k < n; k++) pinv[p[k]] = k;  /* invert the permutation */\n",
      "       ^\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c: In function ‘update_A’:\n",
      "    /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:88:3: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "       for (QDLDL_int i = 0; i < Anz; i++) Apermx[AtoAperm[i]] = Anewx[i];\n",
      "       ^\n",
      "    gmake[3]: *** [CMakeFiles/qdldlamd.dir/amd/src/perm.c.o] Error 1\n",
      "    gmake[2]: *** [CMakeFiles/qdldlamd.dir/all] Error 2\n",
      "    gmake[1]: *** [CMakeFiles/qdldlamd.dir/rule] Error 2\n",
      "    gmake: *** [qdldlamd] Error 2\n",
      "    building 'qdldl' extension\n",
      "    creating build\n",
      "    creating build/temp.linux-x86_64-2.7\n",
      "    creating build/temp.linux-x86_64-2.7/cpp\n",
      "    gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/include -fPIC -Ic -Ic/qdldl/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pybind11/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pybind11/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/include/python2.7 -c cpp/wrapper.cpp -o build/temp.linux-x86_64-2.7/cpp/wrapper.o -O3 -std=c++11\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ [enabled by default]\n",
      "    gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/include -fPIC -Ic -Ic/qdldl/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pybind11/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pybind11/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/include/python2.7 -c cpp/qdldl.cpp -o build/temp.linux-x86_64-2.7/cpp/qdldl.o -O3 -std=c++11\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ [enabled by default]\n",
      "    creating build/lib.linux-x86_64-2.7\n",
      "    g++ -pthread -shared -B /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/compiler_compat -L/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib -Wl,-rpath=/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,-rpath,/lib -L/lib -fPIC -I/include build/temp.linux-x86_64-2.7/cpp/wrapper.o build/temp.linux-x86_64-2.7/cpp/qdldl.o /tmp/pip-install-ihyb00/qdldl/c/build/out/libqdldlamd.a -L/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib -lpython2.7 -o build/lib.linux-x86_64-2.7/qdldl.so\n",
      "    g++: error: /tmp/pip-install-ihyb00/qdldl/c/build/out/libqdldlamd.a: No such file or directory\n",
      "    error: command 'g++' failed with exit status 1\n",
      "    ----------------------------------------\n",
      "    ERROR: Failed building wheel for qdldl\n",
      "    Running setup.py clean for qdldl\n",
      "  Failed to build qdldl\n",
      "  Installing collected packages: numpy, scipy, qdldl\n",
      "      Running setup.py install for qdldl: started\n",
      "      Running setup.py install for qdldl: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-ihyb00/qdldl/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-ihyb00/qdldl/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-nMw_7V/install-record.txt --single-version-externally-managed --prefix /tmp/pip-build-env-a1ffiP/normal --compile --install-headers /tmp/pip-build-env-a1ffiP/normal/include/python2.7/qdldl\n",
      "           cwd: /tmp/pip-install-ihyb00/qdldl/\n",
      "      Complete output (45 lines):\n",
      "      running install\n",
      "      running build\n",
      "      running build_ext\n",
      "      -- Floats are OFF\n",
      "      -- Long integers (64bit) are ON\n",
      "      -- Configuring done\n",
      "      -- Generating done\n",
      "      -- Build files have been written to: /tmp/pip-install-ihyb00/qdldl/c/build\n",
      "      Consolidate compiler generated dependencies of target qdldlobject\n",
      "      [  6%] Built target qdldlobject\n",
      "      Consolidate compiler generated dependencies of target qdldlamd\n",
      "      [ 13%] Building C object CMakeFiles/qdldlamd.dir/amd/src/perm.c.o\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c: In function ‘permute_x’:\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:23:5: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "           for (QDLDL_int j = 0 ; j < n ; j++) x[j] = b[P[j]];\n",
      "           ^\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:23:5: note: use option -std=c99 or -std=gnu99 to compile your code\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c: In function ‘permutet_x’:\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:28:5: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "           for (QDLDL_int j = 0 ; j < n ; j++) x[P[j]] = b[j];\n",
      "           ^\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c: In function ‘pinv’:\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:33:3: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "         for (QDLDL_int k = 0; k < n; k++) pinv[p[k]] = k;  /* invert the permutation */\n",
      "         ^\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c: In function ‘update_A’:\n",
      "      /tmp/pip-install-ihyb00/qdldl/c/amd/src/perm.c:88:3: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "         for (QDLDL_int i = 0; i < Anz; i++) Apermx[AtoAperm[i]] = Anewx[i];\n",
      "         ^\n",
      "      gmake[3]: *** [CMakeFiles/qdldlamd.dir/amd/src/perm.c.o] Error 1\n",
      "      gmake[2]: *** [CMakeFiles/qdldlamd.dir/all] Error 2\n",
      "      gmake[1]: *** [CMakeFiles/qdldlamd.dir/rule] Error 2\n",
      "      gmake: *** [qdldlamd] Error 2\n",
      "      building 'qdldl' extension\n",
      "      creating build\n",
      "      creating build/temp.linux-x86_64-2.7\n",
      "      creating build/temp.linux-x86_64-2.7/cpp\n",
      "      gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/include -fPIC -Ic -Ic/qdldl/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pybind11/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pybind11/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/include/python2.7 -c cpp/wrapper.cpp -o build/temp.linux-x86_64-2.7/cpp/wrapper.o -O3 -std=c++11\n",
      "      cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ [enabled by default]\n",
      "      gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/include -fPIC -Ic -Ic/qdldl/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pybind11/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pybind11/include -I/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/include/python2.7 -c cpp/qdldl.cpp -o build/temp.linux-x86_64-2.7/cpp/qdldl.o -O3 -std=c++11\n",
      "      cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ [enabled by default]\n",
      "      creating build/lib.linux-x86_64-2.7\n",
      "      g++ -pthread -shared -B /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/compiler_compat -L/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib -Wl,-rpath=/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,-rpath,/lib -L/lib -fPIC -I/include build/temp.linux-x86_64-2.7/cpp/wrapper.o build/temp.linux-x86_64-2.7/cpp/qdldl.o /tmp/pip-install-ihyb00/qdldl/c/build/out/libqdldlamd.a -L/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib -lpython2.7 -o build/lib.linux-x86_64-2.7/qdldl.so\n",
      "      g++: error: /tmp/pip-install-ihyb00/qdldl/c/build/out/libqdldlamd.a: No such file or directory\n",
      "      error: command 'g++' failed with exit status 1\n",
      "      ----------------------------------------\n",
      "  ERROR: Command errored out with exit status 1: /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-ihyb00/qdldl/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-ihyb00/qdldl/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-nMw_7V/install-record.txt --single-version-externally-managed --prefix /tmp/pip-build-env-a1ffiP/normal --compile --install-headers /tmp/pip-build-env-a1ffiP/normal/include/python2.7/qdldl Check the logs for full command output.\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/bin/python /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p27/lib/python2.7/site-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-a1ffiP/normal --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- qdldl Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install xgboost\n",
    "!pip install imblearn\n",
    "!pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2f4bf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named imblearn.over_sampling",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1623957f60b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named imblearn.over_sampling"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.models import model_from_json\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dropout\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import calendar\n",
    "from bs4 import BeautifulSoup\n",
    "import queue\n",
    "import threading\n",
    "import sys\n",
    "import io\n",
    "from io import StringIO\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48abcf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab533ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fad0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dae4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_name = 'nfl-ml-pff-data' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "# s3 = boto3.resource('s3')\n",
    "# try:\n",
    "#     if  my_region == 'us-east-1':\n",
    "#         s3.create_bucket(Bucket=bucket_name)\n",
    "#     else: \n",
    "#         s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "#     print('S3 bucket created successfully')\n",
    "# except Exception as e:\n",
    "#     print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc39566",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='nfl-ml-pff-data'\n",
    "file_key = 'dftrain_aws.csv'\n",
    "s3uri = 's3://{}/{}'.format(bucket, file_key)\n",
    "df = pd.read_csv(s3uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0096bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec03ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['player','team_name','season','week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query('weekref!=5 or season !=2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db646a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('weekref!=5 or season !=2021')[[p for p in df.columns if (p=='week' or p=='season' or p=='team_name' or 'player' in p or 'fpts' in p) and 'id' not in p and 'count' not in p]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THIS - VERY USEFUL QUERY\n",
    "#This returns all rows where any player column is null, and it shows week, season, and player names\n",
    "df[df[[y for y in df.columns if 'player' in y]].isna().any(axis=1)]\\\n",
    "[[p for p in df.columns if (p=='week' or p=='season' or p=='team_name' \n",
    "                                 or 'player' in p or 'fpts' in p) and 'def' not in p\n",
    "                                  and 'id' not in p and 'count' not in p]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericXCols = [c for c in df.columns if not any(ext in c for ext in ['week','weekly_rank','fpts','fd_points','dk_points',\n",
    "                                                                      'single_game','player','player_id','position',\n",
    "                                                                      'team','name','season','rank_join_helper_id','oppt','starter'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b83146",
   "metadata": {},
   "outputs": [],
   "source": [
    "xAll = df[numericXCols]\n",
    "xAll.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xAll.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bebd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[[y for y in df.columns if 'player' in y]].isna().any(axis=1)][[p for p in df.columns if (p=='week' or p=='season' or p=='team_name' or 'player' in p or 'points' in p) and 'id' not in p and 'count' not in p]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitBit = False\n",
    "past = time.time()\n",
    "scQb = StandardScaler()\n",
    "scWr1 = StandardScaler()\n",
    "scWr2 = StandardScaler()\n",
    "scWr3 = StandardScaler()\n",
    "scRb1 = StandardScaler()\n",
    "scRb2 = StandardScaler()\n",
    "scTe = StandardScaler()\n",
    "#QB\n",
    "print('Start parsing for QB')\n",
    "#dfNonZeroWr1=df[df[\"dk_points_rec1\"]!=0.0]\n",
    "#xWr1=dfNonZeroWr1[numericXCols]\n",
    "basePoints = 'dk_points'\n",
    "yQb=df['dk_points']\n",
    "xQbTrain, xQbTest, yQbTrain, yQbTest = train_test_split(xAll, yQb, test_size=0.2, random_state=101)\n",
    "print('Start 2nd half of QB after ' + str(time.time()-past))\n",
    "if bitBit:\n",
    "    yQbBitTrain = yQbTrain>20\n",
    "    yQbBitTest = yQbTest>20\n",
    "else:\n",
    "    yQbBitTrain = yQbTrain\n",
    "    yQbBitTest = yQbTest\n",
    "scQb.fit(xQbTrain.astype(np.float))\n",
    "xQbStdTrain = scQb.transform(xQbTrain.astype(np.float))\n",
    "xQbStdTest = scQb.transform(xQbTest.astype(np.float))\n",
    "if bitBit:\n",
    "    xQbTrainSmote, yQbTrainSmote = SMOTE.fit_resample(xQbStdTrain, yQbBitTrain)\n",
    "\n",
    "#WR1\n",
    "print('Start parsing for WR1')\n",
    "#dfNonZeroWr1=df[df[\"dk_points_rec1\"]!=0.0]\n",
    "#xWr1=dfNonZeroWr1[numericXCols]\n",
    "yWr1=df[basePoints+'_rec1']\n",
    "xWr1Train, xWr1Test, yWr1Train, yWr1Test = train_test_split(xAll, yWr1, test_size=0.2, random_state=101)\n",
    "print('Start 2nd half of WR1 after ' + str(time.time()-past))\n",
    "if bitBit:\n",
    "    yWr1BitTrain = yWr1Train>20\n",
    "    yWr1BitTest = yWr1Test>20\n",
    "else:\n",
    "    yWr1BitTrain = yWr1Train\n",
    "    yWr1BitTest = yWr1Test\n",
    "scWr1.fit(xWr1Train.astype(np.float))\n",
    "xWr1StdTrain = scWr1.transform(xWr1Train.astype(np.float))\n",
    "xWr1StdTest = scWr1.transform(xWr1Test.astype(np.float))\n",
    "if bitBit:\n",
    "    xWr1TrainSmote, yWr1TrainSmote = SMOTE.fit_resample(xWr1StdTrain, yWr1BitTrain)\n",
    "\n",
    "#WR2\n",
    "print('Start parsing for WR2 after ' + str(time.time()-past))\n",
    "#dfNonZeroWr2=df[df[\"dk_points_rec2\"]!=0.0]\n",
    "#xWr2=dfNonZeroWr2[numericXCols]\n",
    "yWr2=df[basePoints+'_rec2']\n",
    "xWr2Train, xWr2Test, yWr2Train, yWr2Test = train_test_split(xAll, yWr2, test_size=0.2, random_state=101)\n",
    "xWr2Train.fillna(0,inplace=True)\n",
    "print('Start 2nd half of WR2 after ' + str(time.time()-past))\n",
    "if bitBit:\n",
    "    yWr2BitTrain = yWr2Train>20\n",
    "    yWr2BitTest = yWr2Test>20\n",
    "else:\n",
    "    yWr2BitTrain = yWr2Train\n",
    "    yWr2BitTest = yWr2Test\n",
    "scWr2.fit(xWr2Train.astype(np.float))\n",
    "xWr2StdTrain = scWr2.transform(xWr2Train.astype(np.float))\n",
    "xWr2StdTest = scWr2.transform(xWr2Test.astype(np.float))\n",
    "if bitBit:\n",
    "    xWr2TrainSmote, yWr2TrainSmote = SMOTE.fit_resample(xWr2StdTrain, yWr2BitTrain)\n",
    "\n",
    "#WR3\n",
    "print('Start parsing for WR3 after ' + str(time.time()-past))\n",
    "#dfNonZeroWr3=df[df[\"dk_points_rec3\"]!=0.0]\n",
    "#xWr3=dfNonZeroWr3[numericXCols]\n",
    "yWr3=df[basePoints+'_rec3']\n",
    "xWr3Train, xWr3Test, yWr3Train, yWr3Test = train_test_split(xAll, yWr3, test_size=0.2, random_state=101)\n",
    "print('Start 2nd half of WR3 after ' + str(time.time()-past))\n",
    "if bitBit:\n",
    "    yWr3BitTrain = yWr3Train>20\n",
    "    yWr3BitTest = yWr3Test>20\n",
    "else:\n",
    "    yWr3BitTrain = yWr3Train\n",
    "    yWr3BitTest = yWr3Test\n",
    "scWr3.fit(xWr3Train.astype(np.float))\n",
    "xWr3StdTrain = scWr3.transform(xWr3Train.astype(np.float))\n",
    "xWr3StdTest = scWr3.transform(xWr3Test.astype(np.float))\n",
    "if bitBit:\n",
    "    xWr3TrainSmote, yWr3TrainSmote = SMOTE.fit_resample(xWr3StdTrain, yWr3BitTrain)\n",
    "\n",
    "#RB1\n",
    "print('Start parsing for RB1 after ' + str(time.time()-past))\n",
    "#dfNonZeroRb1=df[df[\"dk_points_rus1\"]!=0.0]\n",
    "#xRb1=dfNonZeroRb1[numericXCols]\n",
    "yRb1=df[basePoints+'_rus1']\n",
    "xRb1Train, xRb1Test, yRb1Train, yRb1Test = train_test_split(xAll, yRb1, test_size=0.2, random_state=101)\n",
    "print('Start 2nd half of RB1 after ' + str(time.time()-past))\n",
    "if bitBit:\n",
    "    yRb1BitTrain = yRb1Train>20\n",
    "    yRb1BitTest = yRb1Test>20\n",
    "else:\n",
    "    yRb1BitTrain = yRb1Train\n",
    "    yRb1BitTest = yRb1Test\n",
    "scRb1.fit(xRb1Train.astype(np.float))\n",
    "xRb1StdTrain = scRb1.transform(xRb1Train.astype(np.float))\n",
    "xRb1StdTest = scRb1.transform(xRb1Test.astype(np.float))\n",
    "if bitBit:\n",
    "    xRb1TrainSmote, yRb1TrainSmote = SMOTE.fit_resample(xRb1StdTrain, yRb1BitTrain)\n",
    "\n",
    "#RB2\n",
    "print('Start parsing for RB2 after ' + str(time.time()-past))\n",
    "#dfNonZeroRb2=df[df[\"dk_points_rus2\"]!=0.0]\n",
    "#xRb2=dfNonZeroRb2[numericXCols]\n",
    "yRb2=df[basePoints+'_rus2']\n",
    "xRb2Train, xRb2Test, yRb2Train, yRb2Test = train_test_split(xAll, yRb2, test_size=0.2, random_state=101)\n",
    "print('Start 2nd half of RB2 after ' + str(time.time()-past))\n",
    "if bitBit:\n",
    "    yRb2BitTrain = yRb2Train>20\n",
    "    yRb2BitTest = yRb2Test>20\n",
    "else:\n",
    "    yRb2BitTrain = yRb2Train\n",
    "    yRb2BitTest = yRb2Test\n",
    "scRb2.fit(xRb2Train.astype(np.float))\n",
    "xRb2StdTrain = scRb2.transform(xRb2Train.astype(np.float))\n",
    "xRb2StdTest = scRb2.transform(xRb2Test.astype(np.float))\n",
    "if bitBit:\n",
    "    xRb2TrainSmote, yRb2TrainSmote = SMOTE.fit_resample(xRb2StdTrain, yRb2BitTrain)\n",
    "print('Finished after ' + str(time.time()-past))\n",
    "\n",
    "#TE\n",
    "print('Start parsing for TE after ' + str(time.time()-past))\n",
    "#dfNonZeroRb2=df[df[\"dk_points_rus2\"]!=0.0]\n",
    "#xRb2=dfNonZeroRb2[numericXCols]\n",
    "yTe=df[basePoints+'_te']\n",
    "xTeTrain, xTeTest, yTeTrain, yTeTest = train_test_split(xAll, yTe, test_size=0.2, random_state=101)\n",
    "print('Start 2nd half of TE after ' + str(time.time()-past))\n",
    "if bitBit:\n",
    "    yTeBitTrain = yTeTrain>20\n",
    "    yTeBitTest = yTeTest>20\n",
    "else:\n",
    "    yTeBitTrain = yTeTrain\n",
    "    yTeBitTest = yTeTest\n",
    "scTe.fit(xTeTrain.astype(np.float))\n",
    "xTeStdTrain = scTe.transform(xTeTrain.astype(np.float))\n",
    "xTeStdTest = scTe.transform(xTeTest.astype(np.float))\n",
    "if bitBit:\n",
    "    xTeTrainSmote, yTeTrainSmote = SMOTE.fit_resample(xTeStdTrain, yTeBitTrain)\n",
    "print('Finished after ' + str(time.time()-past))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(activation = 'relu', \n",
    "                          input_dim = len(xAll.columns), \n",
    "                          units = 5000,#len(xYardsTrain.columns), \n",
    "                          kernel_initializer = 'uniform', \n",
    "                          #W_regularizer=l2(0.001), this is the same as kernel_regularizer, and Keras wants you to use this\n",
    "                          kernel_regularizer=l2(0.001)))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(activation = 'relu', units = 10, kernel_initializer = 'uniform', kernel_regularizer='l1'))\n",
    "#classifierYards.add(Dropout(0.1))\n",
    "#classifier.add(Dense(1,activation='sigmoid'))\n",
    "classifier.add(Dense(1))\n",
    "#https://keras.io/api/losses/regression_losses/#meansquarederror-class\n",
    "opt_adam = tf.keras.optimizers.Adam(clipnorm=1.0)\n",
    "opt_adam = tf.keras.optimizers.Adam(clipvalue=0.5)\n",
    "classifier.compile(optimizer = opt_adam, loss = 'mean_squared_error')#, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdedf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierQb=clone_model(classifier)\n",
    "classifierQb.compile(optimizer = opt_adam, loss = 'mean_squared_error')\n",
    "classifierWr1=clone_model(classifier)\n",
    "classifierWr1.compile(optimizer = opt_adam, loss = 'mean_squared_error')\n",
    "classifierWr2=clone_model(classifier)\n",
    "classifierWr2.compile(optimizer = opt_adam, loss = 'mean_squared_error')\n",
    "classifierWr3=clone_model(classifier)\n",
    "classifierWr3.compile(optimizer = opt_adam, loss = 'mean_squared_error')\n",
    "classifierRb1=clone_model(classifier)\n",
    "classifierRb1.compile(optimizer = opt_adam, loss = 'mean_squared_error')\n",
    "classifierRb2=clone_model(classifier)\n",
    "classifierRb2.compile(optimizer = opt_adam, loss = 'mean_squared_error')\n",
    "classifierTe=clone_model(classifier)\n",
    "classifierTe.compile(optimizer = opt_adam, loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ce09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "client.download_file(bucket,\n",
    "                     'classifierQb_20211010.h5',\n",
    "                     'classifierQb_20211010.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a82bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierQb.load_weights('classifierQb_20211117.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_file_key = 'classifierYards_20211005.h5'\n",
    "# s3WeightsUri = 's3://{}/{}'.format(bucket, weights_file_key)\n",
    "\n",
    "# classifierQb.load_weights(s3WeightsUri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff87b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDict[1]=classifierQb\n",
    "modelDict[3]=classifier3\n",
    "modelDict[4]=classifier4\n",
    "modelDict[5]=classifier5\n",
    "modelDict[6]=classifier6\n",
    "modelDict[7]=classifier7\n",
    "modelDict[8]=classifier8\n",
    "modelDict[9]=classifier9\n",
    "modelDict[10]=classifier10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b937aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83fde88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da59e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094e0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4186ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193aa31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6a8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d9987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241dd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e03883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4147936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f6b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p27",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
